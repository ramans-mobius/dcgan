name: Convert DCGAN Outputs for CDN Upload
description: Converts DCGAN outputs (generated samples, metrics) to format compatible with UploadToCDN brick.
inputs:
  - {name: generated_samples, type: Dataset, description: "Generated samples from Train brick"}
  - {name: evaluation_samples, type: Dataset, description: "Evaluation samples from Evaluate brick"}
  - {name: epoch_loss, type: String, description: "Training metrics JSON"}
  - {name: eval_metrics, type: Metrics, description: "Evaluation metrics"}
  - {name: preprocessing_info, type: Data, description: "Preprocessing info JSON"}
outputs:
  - {name: upload_package, type: Dataset, description: "Pickled package for CDN upload"}
  - {name: config_string, type: String, description: "JSON config for UploadToCDN"}
implementation:
  container:
    image: python:3.8-slim
    command:
      - python3
      - -u
      - -c
    args:
      - |
        import os
        import json
        import pickle
        import argparse
        from datetime import datetime
        import torch
        from torchvision.utils import make_grid
        from PIL import Image
        import io

        parser = argparse.ArgumentParser()
        parser.add_argument('--generated_samples', type=str, required=True)
        parser.add_argument('--evaluation_samples', type=str, required=True)
        parser.add_argument('--epoch_loss', type=str, required=True)
        parser.add_argument('--eval_metrics', type=str, required=True)
        parser.add_argument('--preprocessing_info', type=str, required=True)
        parser.add_argument('--upload_package', type=str, required=True)
        parser.add_argument('--config_string', type=str, required=True)
        args = parser.parse_args()

        print("Converting DCGAN outputs for CDN upload...")

        # Load all data
        with open(args.generated_samples, 'rb') as f:
            train_samples = pickle.load(f)
        
        with open(args.evaluation_samples, 'rb') as f:
            eval_samples = pickle.load(f)
        
        with open(args.epoch_loss, 'r') as f:
            training_metrics = json.load(f)
        
        with open(args.eval_metrics, 'r') as f:
            eval_metrics = json.load(f)
        
        with open(args.preprocessing_info, 'r') as f:
            preprocess_info = json.load(f)

        # Create sample grids for visualization
        def create_sample_grid(samples, nrow=8):
            if samples is not None and len(samples) > 0:
                grid = make_grid(samples[:min(64, len(samples))], nrow=nrow, normalize=True, value_range=(-1, 1))
                return grid
            return None

        train_grid = create_sample_grid(train_samples)
        eval_grid = create_sample_grid(eval_samples)

        # Create upload package
        upload_package = {
            'timestamp': datetime.now().isoformat(),
            'package_type': 'DCGAN_Outputs',
            'contents': {
                'training_samples': train_samples.shape if train_samples is not None else None,
                'evaluation_samples': eval_samples.shape if eval_samples is not None else None,
                'training_metrics': training_metrics,
                'evaluation_metrics': eval_metrics,
                'preprocessing_info': preprocess_info
            },
            'visualization_ready': train_grid is not None or eval_grid is not None
        }

        # Save upload package
        output_dir = os.path.dirname(args.upload_package)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)

        with open(args.upload_package, 'wb') as f:
            pickle.dump(upload_package, f)

        print(f"Saved upload package to: {args.upload_package}")

        # Create config string for UploadToCDN
        config = {
            'upload_timestamp': datetime.now().isoformat(),
            'content_type': 'DCGAN_Outputs',
            'files': {
                'generated_samples': 'pickle',
                'training_metrics': 'json',
                'evaluation_metrics': 'json'
            },
            'metadata': {
                'training_samples': train_samples.shape if train_samples is not None else 'None',
                'evaluation_samples': eval_samples.shape if eval_samples is not None else 'None',
                'model_type': eval_metrics.get('model_type', 'DCGAN'),
                'training_method': eval_metrics.get('training_method', 'unknown')
            }
        }

        with open(args.config_string, 'w') as f:
            f.write(json.dumps(config, indent=2))

        print(f"Saved config string to: {args.config_string}")
        print("Conversion completed successfully!")
      - --generated_samples
      - {inputPath: generated_samples}
      - --evaluation_samples
      - {inputPath: evaluation_samples}
      - --epoch_loss
      - {inputPath: epoch_loss}
      - --eval_metrics
      - {inputPath: eval_metrics}
      - --preprocessing_info
      - {inputPath: preprocessing_info}
      - --upload_package
      - {outputPath: upload_package}
      - --config_string
      - {outputPath: config_string}
