name: GAN Build Model
description: Instantiates either DCGAN or VanillaGAN model using GANFactory based on configuration
inputs:
  - name: config_str
    type: String
    description: Model configuration as JSON string (must include model_type: 'dcgan' or 'vanilla_gan')
  - name: model_name
    type: String
    description: GAN model architecture name ('dcgan' or 'vanilla_gan')
outputs:
  - name: model_out
    type: Model
  - name: config_updated
    type: String
  - name: model_info_out
    type: String

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v34
    command:
      - sh
      - -c
      - |
        # Install compatible torchvision for torch 2.0.1
        pip install torchvision==0.15.2 --quiet
        echo "Torchvision 0.15.2 installed (compatible with torch 2.0.1)"
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch, argparse, json, os, pickle, sys
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--config_str', type=str, required=True)
        parser.add_argument('--model_name', type=str, required=True)
        parser.add_argument('--model_out', type=str, required=True)
        parser.add_argument('--config_updated', type=str, required=True)
        parser.add_argument('--model_info_out', type=str, required=True)
        args = parser.parse_args()

        print('Starting GAN Model Builder')
        
        # Parse configuration
        config = json.loads(args.config_str)
        model_config = config.get('model', {})
        
        # Determine model type from model_name
        model_type = args.model_name.lower()
        if model_type not in ['dcgan', 'vanilla_gan']:
            raise ValueError(f"model_name must be 'dcgan' or 'vanilla_gan', got '{model_type}'")
        
        print(f"Building {model_type.upper()} model...")
        
        # Set default values based on model type
        if model_type == 'dcgan':
            defaults = {
                'image_size': 64,
                'channels': 3,
                'latent_dim': 100,
                'batch_size': 128,
                'learning_rate': 0.0002,
                'training_algorithm': 'backprop',
                'use_wgan': True,
                'generator_features': 64,
                'discriminator_features': 64,
                'epochs': 100,
                'n_critic': 5,
                'device': 'cuda' if torch.cuda.is_available() else 'cpu'
            }
        else:  # vanilla_gan
            defaults = {
                'input_dim': 784,
                'latent_dim': 100,
                'batch_size': 64,
                'learning_rate': 0.0002,
                'training_algorithm': 'backprop',
                'generator_layers': [256, 512],
                'discriminator_layers': [512, 256],
                'epochs': 100,
                'device': 'cuda' if torch.cuda.is_available() else 'cpu'
            }
        
        # Update model_config with defaults if not provided
        for param, default_value in defaults.items():
            if param not in model_config:
                print(f"{param} not found, using default: {default_value}")
                model_config[param] = default_value
        
        # Add model_type to config
        model_config['model_type'] = model_type
        
        # Update the main config
        config['model'] = model_config
        config['model_type'] = model_type
        
        try:
            # Try different import strategies for GANFactory
            import_strategies = [
                'nesy_factory.GANs',
                'nesy_factory.GANs.factory',
                'nesy_factory.GANs.dcgan',
                'nesy_factory.GANs.vanilla_gan'
            ]
            
            GANFactory = None
            create_gan_model = None
            
            for module_path in import_strategies:
                try:
                    print(f'Trying import from {module_path}...')
                    module = __import__(module_path, fromlist=[''])
                    
                    # Look for factory functions
                    if hasattr(module, 'create_gan_model'):
                        create_gan_model = getattr(module, 'create_gan_model')
                        print(f'Found create_gan_model in {module_path}')
                        break
                    elif hasattr(module, 'create_dcgan') and model_type == 'dcgan':
                        create_gan_model = getattr(module, 'create_dcgan')
                        print(f'Found create_dcgan in {module_path}')
                        break
                    elif hasattr(module, 'create_vanilla_gan') and model_type == 'vanilla_gan':
                        create_gan_model = getattr(module, 'create_vanilla_gan')
                        print(f'Found create_vanilla_gan in {module_path}')
                        break
                        
                except ImportError as e:
                    print(f'Import from {module_path} failed: {e}')
                    continue
            
            if create_gan_model is None:
                # Try direct import of factory functions
                try:
                    from nesy_factory.GANs import create_gan_model
                    print('Imported create_gan_model directly')
                except ImportError:
                    try:
                        from nesy_factory.GANs.factory import create_gan_model
                        print('Imported create_gan_model from factory')
                    except ImportError as e:
                        raise ImportError(f"Could not find GAN factory functions: {e}")
            
            # Create the GAN model
            print(f'Creating {model_type.upper()} model with config:')
            for key, value in model_config.items():
                print(f'  {key}: {value}')
            
            if model_type == 'dcgan':
                # Handle DCGAN specific config
                dcgan_config = {
                    'image_size': model_config.get('image_size', 64),
                    'channels': model_config.get('channels', 3),
                    'latent_dim': model_config.get('latent_dim', 100),
                    'training_algorithm': model_config.get('training_algorithm', 'backprop'),
                    'use_forward_forward': model_config.get('training_algorithm', '').lower() == 'forward_forward',
                    'use_cafo': model_config.get('training_algorithm', '').lower() == 'cafo',
                    'batch_size': model_config.get('batch_size', 128),
                    'learning_rate': model_config.get('learning_rate', 0.0002),
                    'beta1': 0.5,
                    'epochs': model_config.get('epochs', 100),
                    'device': 'cuda' if torch.cuda.is_available() else 'cpu'
                }
                
                # Add architecture-specific parameters if provided
                if 'generator_layers' in model_config and model_config['generator_layers']:
                    dcgan_config['generator_layers'] = model_config['generator_layers']
                
                if 'discriminator_layers' in model_config and model_config['discriminator_layers']:
                    dcgan_config['discriminator_layers'] = model_config['discriminator_layers']
                
                if 'use_wgan' in model_config:
                    dcgan_config['use_wgan'] = model_config['use_wgan']
                
                if 'generator_features' in model_config:
                    dcgan_config['generator_features'] = model_config['generator_features']
                
                if 'discriminator_features' in model_config:
                    dcgan_config['discriminator_features'] = model_config['discriminator_features']
                
                model = create_gan_model('dcgan', dcgan_config)
                
            else:  # vanilla_gan
                # Handle VanillaGAN specific config
                vanilla_config = {
                    'input_dim': model_config.get('input_dim', 784),
                    'latent_dim': model_config.get('latent_dim', 100),
                    'training_algorithm': model_config.get('training_algorithm', 'backprop'),
                    'use_forward_forward': model_config.get('training_algorithm', '').lower() == 'forward_forward',
                    'use_cafo': model_config.get('training_algorithm', '').lower() == 'cafo',
                    'generator_layers': model_config.get('generator_layers', [256, 512]),
                    'discriminator_layers': model_config.get('discriminator_layers', [512, 256]),
                    'batch_size': model_config.get('batch_size', 64),
                    'lr': model_config.get('learning_rate', 0.0002),
                    'epochs': model_config.get('epochs', 100),
                    'device': 'cuda' if torch.cuda.is_available() else 'cpu'
                }
                
                model = create_gan_model('vanilla_gan', vanilla_config)
            
            print(f'{model_type.upper()} model created successfully')
            print(f'Model class: {type(model).__name__}')
            
            # Get model info
            model_info = {}
            try:
                if hasattr(model, 'get_model_info'):
                    model_info = model.get_model_info()
                elif hasattr(model, '__dict__'):
                    model_info = {
                        'model_type': model_type,
                        'model_class': type(model).__name__,
                        'generator_parameters': sum(p.numel() for p in model.generator.parameters()),
                        'discriminator_parameters': sum(p.numel() for p in model.discriminator.parameters()),
                        'config': model.config if hasattr(model, 'config') else model_config
                    }
            except Exception as e:
                print(f'Could not get model info: {e}')
                model_info = {
                    'model_type': model_type,
                    'model_class': type(model).__name__,
                    'note': 'Model info retrieval failed'
                }
            
        except Exception as e:
            print(f'Failed to create model: {e}')
            import traceback
            traceback.print_exc()
            exit(1)

        # Combine config and model_info
        combined_info = {
            **model_info,
            **config,
            'model_name': model_type,
            'device': 'cuda' if torch.cuda.is_available() else 'cpu'
        }

        # Create output directories
        os.makedirs(os.path.dirname(args.model_out), exist_ok=True)
        os.makedirs(os.path.dirname(args.config_updated), exist_ok=True)
        os.makedirs(os.path.dirname(args.model_info_out), exist_ok=True)

        # Save model (pickle the whole object)
        with open(args.model_out, 'wb') as f:
            pickle.dump(model, f)
        print(f"Model saved to: {args.model_out}")

        # Save updated config
        with open(args.config_updated, 'w') as f:
            json.dump(config, f, indent=2)
            
        # Save combined info
        with open(args.model_info_out, 'w') as f:
            json.dump(combined_info, f, indent=2)

        print(f"Updated config saved to: {args.config_updated}")
        print(f"Model info saved to: {args.model_info_out}")
        
        # Print model summary
        print("\nModel Summary:")
        print(f"  Type: {model_type.upper()}")
        print(f"  Model Class: {type(model).__name__}")
        if 'generator_parameters' in model_info:
            print(f"  Generator Parameters: {model_info['generator_parameters']:,}")
        if 'discriminator_parameters' in model_info:
            print(f"  Discriminator Parameters: {model_info['discriminator_parameters']:,}")
        print(f"  Training Algorithm: {model_config.get('training_algorithm', 'backprop')}")
        print(f"  Device: {'cuda' if torch.cuda.is_available() else 'cpu'}")

    args:
      - --model_name
      - {inputValue: model_name}
      - --config_str
      - {inputValue: config_str}
      - --model_out
      - {outputPath: model_out}
      - --config_updated
      - {outputPath: config_updated}
      - --model_info_out
      - {outputPath: model_info_out}
