name: Preprocess Dataset
description: Preprocesses dataset for DCGAN training, compatible with LoadDataset outputs.
inputs:
  - name: train_data
    type: Dataset
  - name: test_data
    type: Dataset
  - name: dataset_info
    type: DatasetInfo
  - name: data_config
    type: String
    description: "Data configuration from LoadDataset"
  - name: model_type
    type: String
    default: "dcgan"
    description: "Model type: 'dcgan', 'resnet', 'cnn', 'vanilla_gan'"
  - name: preprocessing_config
    type: String
    default: "{}"
    description: "Additional preprocessing configuration"
outputs:
  - name: processed_data
    type: Dataset
  - name: preprocess_info
    type: String
    description: "Preprocessing information"
  - name: model_config
    type: String
    description: "Model configuration for next steps"
implementation:
  container:
    image: nikhilv215/nesy-factory:v22
    command:
      - sh
      - -c
      - |
        python -c "
        import sys, os, pickle, json, base64, io
        import numpy as np
        import torch
        import torchvision.transforms as transforms
        from torch.utils.data import Dataset, DataLoader
        from PIL import Image
        import warnings
        warnings.filterwarnings('ignore')
        
        print('Starting Dataset Preprocessing')
        
        # Parse arguments
        train_data_path = sys.argv[1]
        test_data_path = sys.argv[2]
        dataset_info_path = sys.argv[3]
        data_config_str = sys.argv[4]
        model_type = sys.argv[5]
        preprocessing_config_str = sys.argv[6]
        processed_data_path = sys.argv[7]
        preprocess_info_path = sys.argv[8]
        model_config_path = sys.argv[9]
        
        print('Model Type: ' + model_type)
        
        # Load data
        with open(train_data_path, 'rb') as f:
            train_data = pickle.load(f)
        
        with open(test_data_path, 'rb') as f:
            test_data = pickle.load(f)
        
        with open(dataset_info_path, 'rb') as f:
            dataset_info = pickle.load(f)
        
        # Parse configurations
        try:
            data_config = json.loads(data_config_str)
        except:
            data_config = {}
        
        try:
            preprocessing_config = json.loads(preprocessing_config_str)
        except:
            preprocessing_config = {}
        
        print('Data Summary:')
        print('  Train samples: ' + str(len(train_data)))
        print('  Test samples: ' + str(len(test_data)))
        print('  Classes: ' + str(dataset_info.get('classes', [])))
        print('  Dataset type: ' + data_config.get('dataset_type', 'unknown'))
        
        # Define processed dataset class
        class ProcessedDataset(Dataset):
            def __init__(self, data_list, transform=None, is_gan=False):
                self.data_list = data_list
                self.transform = transform
                self.is_gan = is_gan
            
            def __len__(self):
                return len(self.data_list)
            
            def __getitem__(self, idx):
                item = self.data_list[idx]
                
                try:
                    # Decode base64 image
                    img_data = base64.b64decode(item['image_data'])
                    img = Image.open(io.BytesIO(img_data))
                    
                    # Convert to RGB if needed
                    if img.mode != 'RGB' and img.mode != 'L':
                        img = img.convert('RGB')
                    
                    # Apply transform
                    if self.transform:
                        img = self.transform(img)
                    
                    # For GANs, return only image
                    if self.is_gan:
                        return img
                    
                    # For classification, return image and label
                    label_str = item.get('label', '0')
                    label_map = dataset_info.get('label_to_idx', {})
                    
                    if label_str in label_map:
                        label = label_map[label_str]
                    else:
                        # Try to convert to int
                        try:
                            label = int(label_str)
                        except:
                            label = 0
                    
                    return img, label
                    
                except Exception as e:
                    print('Error processing item ' + str(idx) + ': ' + str(e))
                    # Return zeros as fallback
                    img_size = preprocessing_config.get('image_size', 64)
                    channels = data_config.get('channels', 3)
                    
                    if self.is_gan:
                        return torch.zeros(channels, img_size, img_size)
                    else:
                        return torch.zeros(channels, img_size, img_size), 0
        
        # Determine image size and channels
        target_size = preprocessing_config.get('image_size', data_config.get('image_size', 64))
        channels = data_config.get('channels', 3)
        
        print('Preprocessing Parameters:')
        print('  Target size: ' + str(target_size) + 'x' + str(target_size))
        print('  Channels: ' + str(channels))
        print('  Model type: ' + model_type)
        
        # Create transforms based on model type
        if model_type == 'dcgan':
            # DCGAN requires normalization to [-1, 1]
            transform = transforms.Compose([
                transforms.Resize(target_size),
                transforms.CenterCrop(target_size),
                transforms.ToTensor(),
                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
            ])
            is_gan = True
            
        elif model_type == 'vanilla_gan':
            # Vanilla GAN (grayscale usually)
            if channels == 1:
                transform = transforms.Compose([
                    transforms.Resize(target_size),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5,), (0.5,))
                ])
            else:
                transform = transforms.Compose([
                    transforms.Resize(target_size),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                ])
            is_gan = True
            
        elif model_type == 'resnet':
            # ResNet expects specific normalization
            if channels == 1:
                # Convert grayscale to 3-channel for ResNet
                transform = transforms.Compose([
                    transforms.Resize(256),
                    transforms.CenterCrop(224),
                    transforms.Grayscale(num_output_channels=3),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
                ])
            else:
                transform = transforms.Compose([
                    transforms.Resize(256),
                    transforms.CenterCrop(224),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
                ])
            is_gan = False
            
        elif model_type == 'cnn':
            # Generic CNN
            if channels == 1:
                transform = transforms.Compose([
                    transforms.Resize(target_size),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5,), (0.5,))
                ])
            else:
                transform = transforms.Compose([
                    transforms.Resize(target_size),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                ])
            is_gan = False
            
        else:
            # Default transform
            transform = transforms.Compose([
                transforms.Resize(target_size),
                transforms.ToTensor(),
                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
            ])
            is_gan = 'gan' in model_type.lower()
        
        # Create processed datasets
        train_dataset = ProcessedDataset(train_data, transform, is_gan)
        
        if test_data and len(test_data) > 0:
            test_dataset = ProcessedDataset(test_data, transform, is_gan)
        else:
            test_dataset = None
            print('Warning: No test data available')
        
        # Create data wrapper
        data_wrapper = {
            'train_dataset': train_dataset,
            'test_dataset': test_dataset,
            'num_classes': len(dataset_info.get('classes', [])),
            'class_names': dataset_info.get('classes', []),
            'label_to_idx': dataset_info.get('label_to_idx', {}),
            'image_size': target_size,
            'channels': channels,
            'model_type': model_type,
            'is_gan': is_gan,
            'dataset_info': dataset_info,
            'has_test_data': test_dataset is not None
        }
        
        # Save processed data
        output_dir = os.path.dirname(processed_data_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        
        with open(processed_data_path, 'wb') as f:
            pickle.dump(data_wrapper, f)
        
        # Create preprocessing info
        preprocess_info = {
            'model_type': model_type,
            'image_size': target_size,
            'channels': channels,
            'is_gan': is_gan,
            'train_samples': len(train_dataset),
            'test_samples': len(test_dataset) if test_dataset else 0,
            'num_classes': len(dataset_info.get('classes', [])),
            'transform_applied': True,
            'normalization': '[-1,1]' if is_gan else '[0,1]',
            'success': True
        }
        
        output_dir_info = os.path.dirname(preprocess_info_path)
        if output_dir_info and not os.path.exists(output_dir_info):
            os.makedirs(output_dir_info, exist_ok=True)
        
        with open(preprocess_info_path, 'w') as f:
            json.dump(preprocess_info, f, indent=2)
        
        # Create model configuration for next steps
        if model_type == 'dcgan':
            # Generate DCGAN configuration
            import math
            
            # Calculate architecture based on image size
            num_gen_layers = max(2, int(math.log2(target_size / 4)))
            gen_layers = [512 // (2 ** i) for i in range(num_gen_layers)]
            
            model_config = {
                'model_type': 'dcgan',
                'image_size': target_size,
                'channels': channels,
                'latent_dim': 100,
                'generator_layers': gen_layers,
                'discriminator_layers': [64 * (2 ** i) for i in range(num_gen_layers - 1)],
                'batch_size': preprocessing_config.get('batch_size', 32),
                'learning_rate': 0.0002,
                'beta1': 0.5,
                'epochs': preprocessing_config.get('epochs', 50),
                'training_algorithm': 'backprop',
                'use_wgan': False,
                'device': 'cuda' if torch.cuda.is_available() else 'cpu'
            }
            
        elif model_type == 'vanilla_gan':
            model_config = {
                'model_type': 'vanilla_gan',
                'image_size': target_size,
                'channels': channels,
                'latent_dim': 100,
                'batch_size': preprocessing_config.get('batch_size', 32),
                'learning_rate': 0.0002,
                'epochs': preprocessing_config.get('epochs', 50)
            }
            
        else:
            # Generic model config
            model_config = {
                'model_type': model_type,
                'image_size': target_size,
                'channels': channels,
                'num_classes': len(dataset_info.get('classes', [])),
                'batch_size': preprocessing_config.get('batch_size', 32),
                'learning_rate': preprocessing_config.get('learning_rate', 0.001)
            }
        
        output_dir_config = os.path.dirname(model_config_path)
        if output_dir_config and not os.path.exists(output_dir_config):
            os.makedirs(output_dir_config, exist_ok=True)
        
        with open(model_config_path, 'w') as f:
            json.dump(model_config, f, indent=2)
        
        print('Preprocessing Complete!')
        print('  Processed train samples: ' + str(len(train_dataset)))
        if test_dataset:
            print('  Processed test samples: ' + str(len(test_dataset)))
        print('  Image size: ' + str(target_size) + 'x' + str(target_size))
        print('  Channels: ' + str(channels))
        print('  Model config saved to: ' + model_config_path)
        " "$0" "$1" "$2" "$3" "$4" "$5" "$6" "$7" "$8" "$9"
    args:
      - {inputPath: train_data}
      - {inputPath: test_data}
      - {inputPath: dataset_info}
      - {inputPath: data_config}
      - {inputValue: model_type}
      - {inputValue: preprocessing_config}
      - {outputPath: processed_data}
      - {outputPath: preprocess_info}
      - {outputPath: model_config}
