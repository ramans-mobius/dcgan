name: 2 Preprocess For GAN
description: Preprocesses dataset for both DCGAN and Vanilla GAN based on model type.
inputs:
  - name: train_data
    type: Dataset
  - name: dataset_info
    type: DatasetInfo
  - name: data_config
    type: String
    description: "Data configuration from LoadDataset"
  - name: model_config
    type: String
    description: "GAN model configuration (dcgan or vanilla_gan)"
outputs:
  - name: processed_data
    type: Dataset
  - name: gan_config
    type: String
    description: "GAN configuration for next step"
implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v33
    command:
      - sh
      - -c
      - |
        # Install dependencies
        pip install torchvision pillow numpy --quiet
        echo "Installed dependencies for GAN preprocessing"
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - "
        import sys, os, pickle, json, base64, io, math
        import numpy as np
        import torch
        import torchvision.transforms as transforms
        from torch.utils.data import Dataset
        from PIL import Image
        
        print('Starting GAN Preprocessing (DCGAN or Vanilla GAN)')
        
        # Parse arguments
        train_data_path = sys.argv[1]
        dataset_info_path = sys.argv[2]
        data_config_str = sys.argv[3]
        model_config_str = sys.argv[4]
        processed_data_path = sys.argv[5]
        gan_config_path = sys.argv[6]
        
        # Load data
        with open(train_data_path, 'rb') as f:
            train_data = pickle.load(f)
        
        with open(dataset_info_path, 'rb') as f:
            dataset_info = pickle.load(f)
        
        # Parse configs
        data_config = json.loads(data_config_str) if data_config_str else {}
        model_config = json.loads(model_config_str) if model_config_str else {}
        
        # Determine model type
        model_type = model_config.get('model_type', 'dcgan').lower()
        is_dcgan = model_type == 'dcgan'
        is_vanilla_gan = model_type == 'vanilla_gan'
        
        if not (is_dcgan or is_vanilla_gan):
            print('Warning: Unknown model type ' + model_type + '. Defaulting to DCGAN.')
            model_type = 'dcgan'
            is_dcgan = True
        
        print('Processing for ' + model_type.upper() + ' GAN')
        print('Loaded ' + str(len(train_data)) + ' samples')
        
        # Get parameters from configs
        image_size = model_config.get('image_size', data_config.get('image_size', 64))
        channels = data_config.get('channels', 3)
        
        # Adjust default sizes based on model type
        if is_vanilla_gan:
            # Vanilla GAN typically uses 28x28 (MNIST size)
            default_size = 28
        else:
            # DCGAN typically uses 64x64
            default_size = 64
        
        target_size = model_config.get('target_size', image_size)
        if target_size != image_size:
            print('Resizing from ' + str(image_size) + ' to ' + str(target_size))
        
        print('Parameters:')
        print('  Model Type: ' + model_type.upper())
        print('  Channels: ' + str(channels))
        print('  Target Size: ' + str(target_size))
        
        # Define dataset class that works for both GAN types
        class GANDataset(Dataset):
            def __init__(self, data_list, transform=None, model_type='dcgan', target_size=64, channels=3):
                self.data_list = data_list
                self.transform = transform
                self.model_type = model_type
                self.target_size = target_size
                self.channels = channels
            
            def __len__(self):
                return len(self.data_list)
            
            def __getitem__(self, idx):
                item = self.data_list[idx]
                
                try:
                    # Decode base64 image
                    img_data = base64.b64decode(item['image_data'])
                    img = Image.open(io.BytesIO(img_data))
                    
                    # Convert to appropriate mode
                    if self.channels == 1 and img.mode != 'L':
                        img = img.convert('L')
                    elif self.channels == 3 and img.mode != 'RGB':
                        img = img.convert('RGB')
                    
                    # Apply transform
                    if self.transform:
                        img = self.transform(img)
                    
                    # For Vanilla GAN, flatten the image
                    if self.model_type == 'vanilla_gan':
                        img = img.view(-1)  # Flatten for fully connected layers
                    
                    return img
                    
                except Exception as e:
                    print('Error processing image ' + str(idx) + ': ' + str(e))
                    # Return appropriate tensor based on model type
                    if self.model_type == 'vanilla_gan':
                        return torch.zeros(self.target_size * self.target_size * self.channels)
                    else:
                        return torch.zeros(self.channels, self.target_size, self.target_size)
        
        # Create transform based on model type
        if is_vanilla_gan:
            # Vanilla GAN: resize to target size, normalize to [-1, 1]
            if channels == 1:
                transform = transforms.Compose([
                    transforms.Resize(target_size),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5,), (0.5,))
                ])
            else:
                transform = transforms.Compose([
                    transforms.Resize(target_size),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                ])
        else:
            # DCGAN: resize and center crop, normalize to [-1, 1]
            if channels == 1:
                transform = transforms.Compose([
                    transforms.Resize(target_size),
                    transforms.CenterCrop(target_size),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5,), (0.5,))
                ])
            else:
                transform = transforms.Compose([
                    transforms.Resize(target_size),
                    transforms.CenterCrop(target_size),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                ])
        
        # Create dataset
        dataset = GANDataset(train_data, transform, model_type, target_size, channels)
        
        # Calculate input dimension based on model type
        if is_vanilla_gan:
            input_dim = target_size * target_size * channels
            print('Vanilla GAN input dimension (flattened): ' + str(input_dim))
        else:
            input_dim = None  # DCGAN doesn't need flattened dimension
        
        # Create data wrapper
        data_wrapper = {
            'dataset': dataset,
            'model_type': model_type,
            'input_dim': input_dim,
            'image_size': target_size,
            'channels': channels,
            'num_samples': len(dataset),
            'is_flattened': is_vanilla_gan
        }
        
        # Save processed data
        output_dir = os.path.dirname(processed_data_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        
        with open(processed_data_path, 'wb') as f:
            pickle.dump(data_wrapper, f)
        
        # Create GAN configuration based on model type
        if is_vanilla_gan:
            # Vanilla GAN configuration
            gan_config = {
                'model_type': 'vanilla_gan',
                'input_dim': input_dim,
                'image_size': target_size,
                'channels': channels,
                'latent_dim': model_config.get('latent_dim', 100),
                'generator_layers': model_config.get('generator_layers', [256, 512]),
                'discriminator_layers': model_config.get('discriminator_layers', [512, 256]),
                'batch_size': model_config.get('batch_size', 64),
                'learning_rate': model_config.get('learning_rate', 0.0002),
                'epochs': model_config.get('epochs', 50),
                'training_algorithm': model_config.get('training_algorithm', 'backprop'),
                'device': 'cuda' if torch.cuda.is_available() else 'cpu'
            }
        else:
            # DCGAN configuration
            # Calculate architecture based on image size
            num_gen_layers = max(2, int(math.log2(target_size / 4)))
            gen_layers = [512 // (2 ** i) for i in range(num_gen_layers)]
            
            gan_config = {
                'model_type': 'dcgan',
                'image_size': target_size,
                'channels': channels,
                'latent_dim': model_config.get('latent_dim', 100),
                'generator_layers': gen_layers,
                'discriminator_layers': [64 * (2 ** i) for i in range(num_gen_layers - 1)],
                'batch_size': model_config.get('batch_size', 32),
                'learning_rate': 0.0002,
                'beta1': 0.5,
                'epochs': model_config.get('epochs', 50),
                'training_algorithm': model_config.get('training_algorithm', 'backprop'),
                'use_wgan': False,
                'device': 'cuda' if torch.cuda.is_available() else 'cpu'
            }
        
        output_dir_config = os.path.dirname(gan_config_path)
        if output_dir_config and not os.path.exists(output_dir_config):
            os.makedirs(output_dir_config, exist_ok=True)
        
        with open(gan_config_path, 'w') as f:
            json.dump(gan_config, f, indent=2)
        
        print('GAN Preprocessing Complete!')
        print('  Model type: ' + model_type.upper())
        print('  Samples processed: ' + str(len(dataset)))
        print('  Image size: ' + str(target_size) + 'x' + str(target_size))
        print('  Channels: ' + str(channels))
        print('  Config saved to: ' + gan_config_path)
        "
    args:
      - {inputPath: train_data}
      - {inputPath: dataset_info}
      - {inputPath: data_config}
      - {inputValue: model_config}
      - {outputPath: processed_data}
      - {outputPath: gan_config}
