name: Preprocess For GAN
description: Preprocesses dataset for both DCGAN and Vanilla GAN based on model type.
inputs:
  - name: train_data
    type: Dataset
  - name: dataset_info
    type: DatasetInfo
  - name: data_config
    type: String
    description: "Data configuration from LoadDataset"
  - name: model_config
    type: String
    default: "{\"model_type\": \"dcgan\"}"
    description: "GAN model configuration (dcgan or vanilla_gan)"
outputs:
  - name: processed_data
    type: Dataset
  - name: gan_config
    type: String
    description: "GAN configuration for next step"
implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v33
    command:
      - sh
      - -c
      - |
        # Install required dependencies first
        pip install torch torchvision pillow numpy --quiet
        echo "Dependencies installed successfully"
        
        # Then run the Python script
        python -c "
        import sys, os, pickle, json, base64, io, math
        import numpy as np
        import torch
        import torchvision.transforms as transforms
        from torch.utils.data import Dataset
        from PIL import Image
        
        print('Starting GAN Preprocessing (DCGAN or Vanilla GAN)')
        
        # Parse arguments
        train_data_path = sys.argv[1]
        dataset_info_path = sys.argv[2]
        data_config_str = sys.argv[3]
        model_config_str = sys.argv[4]
        processed_data_path = sys.argv[5]
        gan_config_path = sys.argv[6]
        
        # Load data
        with open(train_data_path, 'rb') as f:
            train_data = pickle.load(f)
        
        with open(dataset_info_path, 'rb') as f:
            dataset_info = pickle.load(f)
        
        # Parse configs
        try:
            data_config = json.loads(data_config_str) if data_config_str else {}
        except:
            data_config = {}
        
        try:
            model_config = json.loads(model_config_str) if model_config_str else {}
        except:
            model_config = {}
        
        # Determine model type
        model_type = model_config.get('model_type', 'dcgan').lower()
        is_dcgan = model_type == 'dcgan'
        is_vanilla_gan = model_type == 'vanilla_gan'
        
        if not (is_dcgan or is_vanilla_gan):
            print('Warning: Unknown model type ' + model_type + '. Defaulting to DCGAN.')
            model_type = 'dcgan'
            is_dcgan = True
        
        print('Processing for ' + model_type.upper() + ' GAN')
        print('Loaded ' + str(len(train_data)) + ' samples')
        
        # Get parameters from configs
        image_size = model_config.get('image_size', data_config.get('image_size', 64))
        channels = data_config.get('channels', 3)
        
        # Adjust default sizes based on model type
        if is_vanilla_gan:
            default_size = 28
        else:
            default_size = 64
        
        target_size = model_config.get('target_size', image_size)
        if target_size != image_size:
            print('Resizing from ' + str(image_size) + ' to ' + str(target_size))
        
        print('Parameters:')
        print('  Model Type: ' + model_type.upper())
        print('  Channels: ' + str(channels))
        print('  Target Size: ' + str(target_size))
        
        # Define dataset class
        class GANDataset(Dataset):
            def __init__(self, data_list, transform=None, model_type='dcgan', target_size=64, channels=3):
                self.data_list = data_list
                self.transform = transform
                self.model_type = model_type
                self.target_size = target_size
                self.channels = channels
            
            def __len__(self):
                return len(self.data_list)
            
            def __getitem__(self, idx):
                item = self.data_list[idx]
                try:
                    img_data = base64.b64decode(item['image_data'])
                    img = Image.open(io.BytesIO(img_data))
                    
                    if self.channels == 1 and img.mode != 'L':
                        img = img.convert('L')
                    elif self.channels == 3 and img.mode != 'RGB':
                        img = img.convert('RGB')
                    
                    if self.transform:
                        img = self.transform(img)
                    
                    if self.model_type == 'vanilla_gan':
                        img = img.view(-1)
                    
                    return img
                except Exception as e:
                    print('Error processing image ' + str(idx) + ': ' + str(e))
                    if self.model_type == 'vanilla_gan':
                        return torch.zeros(self.target_size * self.target_size * self.channels)
                    else:
                        return torch.zeros(self.channels, self.target_size, self.target_size)
        
        # Create transform
        if is_vanilla_gan:
            if channels == 1:
                transform = transforms.Compose([
                    transforms.Resize(target_size),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5,), (0.5,))
                ])
            else:
                transform = transforms.Compose([
                    transforms.Resize(target_size),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                ])
        else:
            if channels == 1:
                transform = transforms.Compose([
                    transforms.Resize(target_size),
                    transforms.CenterCrop(target_size),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5,), (0.5,))
                ])
            else:
                transform = transforms.Compose([
                    transforms.Resize(target_size),
                    transforms.CenterCrop(target_size),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                ])
        
        # Create dataset
        dataset = GANDataset(train_data, transform, model_type, target_size, channels)
        
        # Calculate input dimension
        if is_vanilla_gan:
            input_dim = target_size * target_size * channels
            print('Vanilla GAN input dimension: ' + str(input_dim))
        else:
            input_dim = None
        
        # Create data wrapper
        data_wrapper = {
            'dataset': dataset,
            'model_type': model_type,
            'input_dim': input_dim,
            'image_size': target_size,
            'channels': channels,
            'num_samples': len(dataset),
            'is_flattened': is_vanilla_gan
        }
        
        # Save processed data
        os.makedirs(os.path.dirname(processed_data_path) or '.', exist_ok=True)
        with open(processed_data_path, 'wb') as f:
            pickle.dump(data_wrapper, f)
        
        # Create GAN configuration
        if is_vanilla_gan:
            gan_config = {
                'model_type': 'vanilla_gan',
                'input_dim': input_dim,
                'image_size': target_size,
                'channels': channels,
                'latent_dim': model_config.get('latent_dim', 100),
                'generator_layers': model_config.get('generator_layers', [256, 512]),
                'discriminator_layers': model_config.get('discriminator_layers', [512, 256]),
                'batch_size': model_config.get('batch_size', 64),
                'learning_rate': model_config.get('learning_rate', 0.0002),
                'epochs': model_config.get('epochs', 50),
                'training_algorithm': model_config.get('training_algorithm', 'backprop'),
                'device': 'cuda' if torch.cuda.is_available() else 'cpu'
            }
        else:
            num_gen_layers = max(2, int(math.log2(target_size / 4)))
            gen_layers = [512 // (2 ** i) for i in range(num_gen_layers)]
            
            gan_config = {
                'model_type': 'dcgan',
                'image_size': target_size,
                'channels': channels,
                'latent_dim': model_config.get('latent_dim', 100),
                'generator_layers': gen_layers,
                'discriminator_layers': [64 * (2 ** i) for i in range(num_gen_layers - 1)],
                'batch_size': model_config.get('batch_size', 32),
                'learning_rate': 0.0002,
                'beta1': 0.5,
                'epochs': model_config.get('epochs', 50),
                'training_algorithm': model_config.get('training_algorithm', 'backprop'),
                'use_wgan': False,
                'device': 'cuda' if torch.cuda.is_available() else 'cpu'
            }
        
        # Save GAN config
        os.makedirs(os.path.dirname(gan_config_path) or '.', exist_ok=True)
        with open(gan_config_path, 'w') as f:
            json.dump(gan_config, f, indent=2)
        
        print('GAN Preprocessing Complete!')
        print('  Model type: ' + model_type.upper())
        print('  Samples processed: ' + str(len(dataset)))
        print('  Image size: ' + str(target_size) + 'x' + str(target_size))
        print('  Channels: ' + str(channels))
        " "$0" "$1" "$2" "$3" "$4" "$5" "$6"
    args:
      - {inputPath: train_data}
      - {inputPath: dataset_info}
      - {inputPath: data_config}
      - {inputValue: model_config}
      - {outputPath: processed_data}
      - {outputPath: gan_config}
