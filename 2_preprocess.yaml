name: ssss Preprocess For GAN Fixed
description: Preprocesses dataset for both DCGAN and Vanilla GAN using nesy_factory.
inputs:
  - name: train_data
    type: Dataset
  - name: dataset_info
    type: DatasetInfo
  - name: data_config
    type: String
    description: "Data configuration from LoadDataset"
  - name: model_config
    type: String
    description: "GAN model configuration (dcgan or vanilla_gan)"
outputs:
  - name: processed_data
    type: Dataset
  - name: gan_config
    type: String
    description: "GAN configuration for next step"
implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v33
    command:
      - sh
      - -c
      - |
        python -c "
        import sys, os, pickle, json, base64, io, math
        import numpy as np
        
        print('Starting GAN Preprocessing with nesy_factory')
        
        # Parse arguments
        train_data_path = sys.argv[1]
        dataset_info_path = sys.argv[2]
        data_config_str = sys.argv[3]
        model_config_str = sys.argv[4]
        processed_data_path = sys.argv[5]
        gan_config_path = sys.argv[6]
        
        # Load data
        with open(train_data_path, 'rb') as f:
            train_data = pickle.load(f)
        
        with open(dataset_info_path, 'rb') as f:
            dataset_info = pickle.load(f)
        
        # Parse configs
        try:
            data_config = json.loads(data_config_str) if data_config_str else {}
        except:
            data_config = {}
        
        try:
            model_config = json.loads(model_config_str) if model_config_str else {}
        except:
            model_config = {}
        
        # Determine model type
        model_type = model_config.get('model_type', 'dcgan').lower()
        
        print('Processing for ' + model_type.upper() + ' GAN')
        print('Loaded ' + str(len(train_data)) + ' samples')
        
        # Use nesy_factory create_default_transforms
        try:
            from nesy_factory.GANs import create_default_transforms
            print('Imported nesy_factory GAN transforms')
        except ImportError as e:
            print(f'Error importing nesy_factory: {e}')
            # Fallback
            import torchvision.transforms as transforms
            create_default_transforms = lambda size: transforms.Compose([
                transforms.Resize(size),
                transforms.CenterCrop(size),
                transforms.ToTensor(),
                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
            ])
        
        # Get parameters
        image_size = model_config.get('image_size', data_config.get('image_size', 64))
        channels = data_config.get('channels', 3)
        target_size = model_config.get('target_size', image_size)
        
        print('Parameters:')
        print('  Model Type: ' + model_type.upper())
        print('  Channels: ' + str(channels))
        print('  Target Size: ' + str(target_size))
        
        # Define dataset class
        class GANDataset:
            def __init__(self, data_list, transform=None, model_type='dcgan', target_size=64, channels=3):
                self.data_list = data_list
                self.transform = transform
                self.model_type = model_type
                self.target_size = target_size
                self.channels = channels
            
            def __len__(self):
                return len(self.data_list)
            
            def __getitem__(self, idx):
                item = self.data_list[idx]
                try:
                    img_data = base64.b64decode(item['image_data'])
                    from PIL import Image
                    import torch
                    
                    img = Image.open(io.BytesIO(img_data))
                    
                    if self.channels == 1 and img.mode != 'L':
                        img = img.convert('L')
                    elif self.channels == 3 and img.mode != 'RGB':
                        img = img.convert('RGB')
                    
                    if self.transform:
                        img = self.transform(img)
                    
                    return img
                except Exception as e:
                    print('Error processing image ' + str(idx) + ': ' + str(e))
                    import torch
                    return torch.zeros(self.channels, self.target_size, self.target_size)
        
        # Create transform using nesy_factory
        transform = create_default_transforms(target_size)
        
        # Create dataset
        dataset = GANDataset(train_data, transform, model_type, target_size, channels)
        
        # Calculate input dimension for vanilla GAN
        if model_type == 'vanilla_gan':
            input_dim = target_size * target_size * channels
            print('Vanilla GAN input dimension: ' + str(input_dim))
        else:
            input_dim = None
        
        # Create data wrapper
        data_wrapper = {
            'dataset': dataset,
            'model_type': model_type,
            'input_dim': input_dim,
            'image_size': target_size,
            'channels': channels,
            'num_samples': len(dataset),
            'is_flattened': model_type == 'vanilla_gan'
        }
        
        # Save processed data
        os.makedirs(os.path.dirname(processed_data_path) or '.', exist_ok=True)
        with open(processed_data_path, 'wb') as f:
            pickle.dump(data_wrapper, f)
        
        # Create GAN configuration compatible with nesy_factory
        if model_type == 'vanilla_gan':
            gan_config = {
                'model_type': 'vanilla_gan',
                'input_dim': input_dim,
                'latent_dim': model_config.get('latent_dim', 100),
                'generator_layers': model_config.get('generator_layers', [256, 512]),
                'discriminator_layers': model_config.get('discriminator_layers', [512, 256]),
                'batch_size': model_config.get('batch_size', 64),
                'learning_rate': model_config.get('learning_rate', 0.0002),
                'epochs': model_config.get('epochs', 50),
                'training_algorithm': model_config.get('training_algorithm', 'backprop'),
                'device': 'cuda' if hasattr(__builtins__, '__import__') and __import__('torch').cuda.is_available() else 'cpu'
            }
        else:
            gan_config = {
                'model_type': 'dcgan',
                'image_size': target_size,
                'channels': channels,
                'latent_dim': model_config.get('latent_dim', 100),
                'generator_layers': model_config.get('generator_layers', []),  # Let DCGANConfig set defaults
                'discriminator_layers': model_config.get('discriminator_layers', []),
                'batch_size': model_config.get('batch_size', 32),
                'learning_rate': model_config.get('learning_rate', 0.0002),
                'epochs': model_config.get('epochs', 50),
                'training_algorithm': model_config.get('training_algorithm', 'backprop'),
                'device': 'cuda' if hasattr(__builtins__, '__import__') and __import__('torch').cuda.is_available() else 'cpu'
            }
        
        # Save GAN config
        os.makedirs(os.path.dirname(gan_config_path) or '.', exist_ok=True)
        with open(gan_config_path, 'w') as f:
            json.dump(gan_config, f, indent=2)
        
        print('GAN Preprocessing Complete!')
        print('  Model type: ' + model_type.upper())
        print('  Samples processed: ' + str(len(dataset)))
        print('  Image size: ' + str(target_size) + 'x' + str(target_size))
        print('  Channels: ' + str(channels))
        " "$0" "$1" "$2" "$3" "$4" "$5" "$6"
    args:
      - {inputPath: train_data}
      - {inputPath: dataset_info}
      - {inputPath: data_config}
      - {inputValue: model_config}
      - {outputPath: processed_data}
      - {outputPath: gan_config}
