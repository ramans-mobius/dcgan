name: DCGAN Image Preprocessor
description: Preprocess images for DCGAN training - resize, normalize, and create train/test splits.
inputs:
  - {name: original_dataset, type: Dataset, description: "Original DataWrapper pickle with images"}
  - {name: train_split_info, type: Data, description: "JSON with train/test split indices"}
  - {name: image_size, type: Integer, optional: true, default: "64", description: "Target image size"}
  - {name: normalize, type: Boolean, optional: true, default: "true", description: "Normalize images to [-1, 1]"}
outputs:
  - {name: train_images, type: Dataset, description: "Pickled train images tensor"}
  - {name: test_images, type: Dataset, description: "Pickled test images tensor"}
  - {name: preprocessing_info, type: Data, description: "JSON with preprocessing details"}
implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v32
    command:
      - sh
      - -c
      - |
        python3 -c "
        import sys, json, os, pickle, torch, numpy as np
        from datetime import datetime
        import io
        from PIL import Image
        from torchvision import transforms

        print('Number of arguments:', len(sys.argv))
        for i, arg in enumerate(sys.argv):
            print(f'  Argument {i}: {arg[:100] if len(str(arg)) > 100 else arg}')
        
        # Get args - sys.argv[0] is the script name, actual args start at 1
        if len(sys.argv) < 8:
            raise ValueError(f'Expected 8 arguments (including script name), got {len(sys.argv)}')
        
        # IMPORTANT: With inputValue, KFP passes the actual file path as a string
        original_dataset_path = sys.argv[1]      # $0
        train_split_info_path = sys.argv[2]      # $1
        image_size = int(sys.argv[3])            # $2
        normalize_str = sys.argv[4]              # $3
        train_images_path = sys.argv[5]          # $4
        test_images_path = sys.argv[6]           # $5
        preprocessing_info_path = sys.argv[7]    # $6

        normalize = normalize_str.lower() == 'true'

        print('Starting DCGAN Image Preprocessing')
        print(f'Image size: {image_size}x{image_size}')
        print(f'Normalize: {normalize}')

        # Load original dataset
        print(f'Loading original dataset from: {original_dataset_path}')
        with open(original_dataset_path, 'rb') as f:
            data_wrapper = pickle.load(f)

        # Load split info
        print(f'Loading split info from: {train_split_info_path}')
        with open(train_split_info_path, 'r') as f:
            split_info = json.load(f)

        train_indices = split_info.get('train_indices', [])
        test_indices = split_info.get('test_indices', [])

        print(f'Original images: {len(data_wrapper.images)}')
        print(f'Train indices: {len(train_indices)}')
        print(f'Test indices: {len(test_indices)}')

        # Define preprocessing transforms
        if normalize:
            transform = transforms.Compose([
                transforms.Resize((image_size, image_size)),
                transforms.ToTensor(),
                transforms.Normalize((0.5,), (0.5,))  # [-1, 1] range
            ])
        else:
            transform = transforms.Compose([
                transforms.Resize((image_size, image_size)),
                transforms.ToTensor(),  # [0, 1] range
            ])

        def process_images(indices, name):
            images = []
            failed = 0
            
            print(f'Processing {name} images...')
            for idx in indices:
                try:
                    img_info = data_wrapper.images[idx]
                    if 'image_data' in img_info:
                        img_bytes = img_info['image_data']
                        pil_img = Image.open(io.BytesIO(img_bytes))
                        
                        # Convert to RGB if needed
                        if pil_img.mode != 'RGB':
                            pil_img = pil_img.convert('RGB')
                        
                        img_tensor = transform(pil_img)
                        images.append(img_tensor)
                        
                        if len(images) % 100 == 0:
                            print(f'  Processed {len(images)} {name} images...')
                            
                except Exception as e:
                    failed += 1
                    print(f'  Failed to process image {idx}: {str(e)[:100]}')
                    continue
            
            if images:
                images_tensor = torch.stack(images)
                print(f'  Successfully processed {len(images)} {name} images')
                print(f'  Failed: {failed}')
                print(f'  Tensor shape: {images_tensor.shape}')
                return images_tensor
            else:
                print(f'  No {name} images could be processed')
                return None

        # Process train and test images
        train_tensor = process_images(train_indices, 'train')
        test_tensor = process_images(test_indices, 'test')

        # Save processed images
        output_dir = os.path.dirname(train_images_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)

        with open(train_images_path, 'wb') as f:
            pickle.dump(train_tensor, f)
        print(f'Saved train images to: {train_images_path}')

        with open(test_images_path, 'wb') as f:
            pickle.dump(test_tensor, f)
        print(f'Saved test images to: {test_images_path}')

        # Create preprocessing info
        preprocessing_info = {
            'timestamp': datetime.now().isoformat(),
            'image_size': image_size,
            'normalized': normalize,
            'train_samples': len(train_tensor) if train_tensor is not None else 0,
            'test_samples': len(test_tensor) if test_tensor is not None else 0,
            'tensor_shape': list(train_tensor.shape) if train_tensor is not None else None,
            'data_range': '[-1, 1]' if normalize else '[0, 1]',
            'original_dataset_info': {
                'total_images': len(data_wrapper.images),
                'classes': data_wrapper.class_names if hasattr(data_wrapper, 'class_names') else [],
                'train_indices_count': len(train_indices),
                'test_indices_count': len(test_indices)
            }
        }

        with open(preprocessing_info_path, 'w') as f:
            json.dump(preprocessing_info, f, indent=2)

        print(f'Saved preprocessing info to: {preprocessing_info_path}')
        print('Image preprocessing completed successfully!')
        " "$0" "$1" "$2" "$3" "$4" "$5" "$6"
    args:
      - {inputValue: original_dataset}    # CHANGED: inputValue instead of inputPath
      - {inputValue: train_split_info}    # CHANGED: inputValue instead of inputPath
      - {inputValue: image_size}
      - {inputValue: normalize}
      - {outputPath: train_images}
      - {outputPath: test_images}
      - {outputPath: preprocessing_info}
