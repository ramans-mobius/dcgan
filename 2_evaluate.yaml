name: 2 Evaluate GAN Model
description: Evaluates trained GAN model and generates metrics.
inputs:
  - name: trained_model
    type: Model
  - name: test_data
    type: Dataset
  - name: training_history
    type: String
  - name: eval_config
    type: String
    description: "Evaluation configuration"
outputs:
  - name: eval_results
    type: String
    description: "Evaluation metrics JSON"
  - name: final_images
    type: Dataset
    description: "Generated images for analysis"
  - name: metrics_summary
    type: String
    description: "Summary of metrics"
implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v33
    command:
      - sh
      - -c
      - |
        python -c "
        import sys, os, pickle, json, base64, io, math, numpy as np
        import torch
        from torch.utils.data import DataLoader
        from PIL import Image
        
        print('Starting GAN Evaluation')
        
        # Parse arguments
        trained_model_path = sys.argv[1]
        test_data_path = sys.argv[2]
        training_history_str = sys.argv[3]
        eval_config_str = sys.argv[4]
        eval_results_path = sys.argv[5]
        final_images_path = sys.argv[6]
        metrics_summary_path = sys.argv[7]
        
        print('Loading model and data...')
        
        # Load trained model
        with open(trained_model_path, 'rb') as f:
            gan_model = pickle.load(f)
        
        # Load test data
        with open(test_data_path, 'rb') as f:
            test_data_wrapper = pickle.load(f)
        
        # Parse configs
        try:
            training_history = json.loads(training_history_str)
        except:
            training_history = {}
        
        try:
            eval_config = json.loads(eval_config_str)
        except:
            eval_config = {}
        
        # Determine model type
        model_type = 'dcgan'
        if hasattr(gan_model, 'config'):
            if hasattr(gan_model.config, 'model_type'):
                model_type = gan_model.config.model_type
            elif hasattr(gan_model.config, 'input_dim'):
                model_type = 'vanilla_gan'
        
        print(f'Evaluating {model_type.upper()} GAN')
        
        # Get dataset from wrapper
        test_dataset = test_data_wrapper.get('dataset')
        if not test_dataset:
            print('No test dataset found')
            test_dataset = []
        
        # Extract model info
        model_info = {
            'model_type': model_type,
            'evaluation_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'device': 'cuda' if torch.cuda.is_available() else 'cpu'
        }
        
        # Add model-specific info
        if hasattr(gan_model, 'config'):
            config_dict = gan_model.config.__dict__ if hasattr(gan_model.config, '__dict__') else gan_model.config
            for key in ['latent_dim', 'image_size', 'channels', 'input_dim', 'training_algorithm']:
                if key in config_dict:
                    model_info[key] = config_dict[key]
        
        # Generate evaluation samples
        sample_count = eval_config.get('num_samples', 100)
        final_images = []
        
        try:
            if hasattr(gan_model, 'generator') and gan_model.generator:
                print(f'Generating {sample_count} samples...')
                
                # Get latent dimension
                latent_dim = model_info.get('latent_dim', 100)
                
                # Generate noise
                gan_model.generator.eval()
                with torch.no_grad():
                    # Generate multiple batches
                    for i in range(0, sample_count, 16):
                        batch_size = min(16, sample_count - i)
                        noise = torch.randn(batch_size, latent_dim)
                        
                        # Add spatial dimensions for DCGAN
                        if model_type == 'dcgan':
                            noise = noise.view(batch_size, latent_dim, 1, 1)
                        
                        # Generate images
                        samples = gan_model.generator(noise).cpu()
                        
                        # Denormalize from [-1, 1] to [0, 1]
                        samples = (samples + 1) / 2
                        samples = torch.clamp(samples, 0, 1)
                        
                        # Convert to base64
                        for j in range(samples.size(0)):
                            sample = samples[j]
                            
                            # Determine image dimensions
                            if len(sample.shape) == 3:
                                # DCGAN format [C, H, W]
                                if sample.shape[0] == 1:  # Grayscale
                                    img_np = sample.squeeze(0).numpy()
                                    img_pil = Image.fromarray((img_np * 255).astype(np.uint8), mode='L')
                                else:  # RGB
                                    img_np = sample.permute(1, 2, 0).numpy()
                                    img_pil = Image.fromarray((img_np * 255).astype(np.uint8), mode='RGB')
                            else:
                                # Vanilla GAN flattened
                                img_size = int(math.sqrt(sample.shape[0]))
                                img_np = sample.view(img_size, img_size).numpy()
                                img_pil = Image.fromarray((img_np * 255).astype(np.uint8), mode='L')
                            
                            # Convert to base64
                            img_bytes = io.BytesIO()
                            img_pil.save(img_bytes, format='PNG')
                            base64_data = base64.b64encode(img_bytes.getvalue()).decode('utf-8')
                            
                            final_images.append({
                                'sample_id': i + j,
                                'image_data': base64_data,
                                'model_type': model_type,
                                'filename': f'{model_type}_sample_{i+j}.png'
                            })
                
                print(f'Generated {len(final_images)} evaluation samples')
        except Exception as e:
            print(f'Error generating samples: {e}')
        
        # Calculate metrics from training history
        metrics = {
            'training_metrics': {},
            'generation_metrics': {},
            'model_info': model_info
        }
        
        # Extract final training metrics
        if training_history and isinstance(training_history, dict):
            for key in ['d_loss', 'g_loss', 'real_score', 'fake_score']:
                if key in training_history and training_history[key]:
                    values = training_history[key]
                    metrics['training_metrics'][f'final_{key}'] = values[-1] if values else 0
                    metrics['training_metrics'][f'min_{key}'] = min(values) if values else 0
                    metrics['training_metrics'][f'max_{key}'] = max(values) if values else 0
                    metrics['training_metrics'][f'avg_{key}'] = sum(values)/len(values) if values else 0
        
        # Calculate stability metrics
        if 'd_loss' in training_history and training_history['d_loss']:
            d_losses = training_history['d_loss']
            if len(d_losses) > 1:
                # Loss convergence
                last_quarter = d_losses[-len(d_losses)//4:]
                first_quarter = d_losses[:len(d_losses)//4]
                convergence = abs(sum(last_quarter)/len(last_quarter) - sum(first_quarter)/len(first_quarter))
                metrics['training_metrics']['loss_convergence'] = convergence
        
        # Generation quality metrics
        metrics['generation_metrics']['samples_generated'] = len(final_images)
        metrics['generation_metrics']['sample_diversity'] = len(final_images) / sample_count if sample_count > 0 else 0
        
        # Model health metrics
        try:
            if hasattr(gan_model, 'generator'):
                gen_params = sum(p.numel() for p in gan_model.generator.parameters())
                metrics['model_info']['generator_params'] = gen_params
            
            if hasattr(gan_model, 'discriminator'):
                disc_params = sum(p.numel() for p in gan_model.discriminator.parameters())
                metrics['model_info']['discriminator_params'] = disc_params
        except:
            pass
        
        # Overall evaluation
        final_d_loss = metrics['training_metrics'].get('final_d_loss', 1.0)
        final_g_loss = metrics['training_metrics'].get('final_g_loss', 1.0)
        
        # Calculate overall score (lower is better)
        loss_score = (final_d_loss + final_g_loss) / 2
        stability_score = metrics['training_metrics'].get('loss_convergence', 1.0)
        
        overall_score = (0.7 * loss_score + 0.3 * stability_score)
        
        metrics['overall_evaluation'] = {
            'overall_score': overall_score,
            'loss_score': loss_score,
            'stability_score': stability_score,
            'sample_quality': metrics['generation_metrics']['sample_diversity'],
            'training_success': overall_score < 0.5,
            'recommendation': 'GOOD' if overall_score < 0.3 else 'FAIR' if overall_score < 0.6 else 'POOR'
        }
        
        # Create summary
        summary = f'''{model_type.upper()} GAN Evaluation Summary:
        • Model Type: {model_type}
        • Training Algorithm: {model_info.get('training_algorithm', 'N/A')}
        • Final D Loss: {final_d_loss:.4f}
        • Final G Loss: {final_g_loss:.4f}
        • Samples Generated: {len(final_images)}
        • Overall Score: {overall_score:.3f} ({metrics['overall_evaluation']['recommendation']})
        • Training Successful: {'✓' if metrics['overall_evaluation']['training_success'] else '✗'}
        '''
        
        print(summary)
        
        # Save outputs
        output_dir = os.path.dirname(eval_results_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        
        with open(eval_results_path, 'w') as f:
            json.dump(metrics, f, indent=2)
        
        with open(final_images_path, 'wb') as f:
            pickle.dump(final_images, f)
        
        with open(metrics_summary_path, 'w') as f:
            f.write(summary)
        
        print('GAN Evaluation Complete!')
        print(f'Results saved to: {eval_results_path}')
        " "$0" "$1" "$2" "$3" "$4" "$5" "$6" "$7"
    args:
      - {inputPath: trained_model}
      - {inputPath: test_data}
      - {inputPath: training_history}
      - {inputValue: eval_config}
      - {outputPath: eval_results}
      - {outputPath: final_images}
      - {outputPath: metrics_summary}
