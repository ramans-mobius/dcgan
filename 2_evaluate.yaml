name: Evaluate GAN Model Comprehensive
description: Comprehensive GAN evaluation with FID, precision, recall, F1, and all metrics.
inputs:
  - name: trained_model
    type: Model
  - name: test_data
    type: Dataset
  - name: training_history
    type: String
  - name: eval_config
    type: String
    description: "Evaluation configuration"
outputs:
  - name: eval_metrics
    type: String
    description: "Complete evaluation metrics JSON"
  - name: generated_images
    type: Dataset
    description: "Generated images for CDN upload"
  - name: evaluation_report
    type: String
    description: "Text summary of all metrics"
implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v33
    command:
      - sh
      - -c
      - |
        # Install torchvision compatible with nesy-factory
        pip install torchvision==0.15.2 scipy scikit-learn --no-deps --quiet
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import sys, os, pickle, json, base64, io, math, time, warnings, argparse
        import numpy as np
        import torch
        from torch.utils.data import DataLoader
        from PIL import Image
        from scipy import linalg
        from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
        from sklearn.neighbors import NearestNeighbors
        warnings.filterwarnings('ignore')
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--trained_model_path', type=str, required=True)
        parser.add_argument('--test_data_path', type=str, required=True)
        parser.add_argument('--training_history_str', type=str, required=True)
        parser.add_argument('--eval_config_str', type=str, required=True)
        parser.add_argument('--eval_metrics_path', type=str, required=True)
        parser.add_argument('--generated_images_path', type=str, required=True)
        parser.add_argument('--evaluation_report_path', type=str, required=True)
        args = parser.parse_args()
        
        print('Starting Comprehensive GAN Evaluation')
        
        # Load trained model
        with open(args.trained_model_path, 'rb') as f:
            gan_model = pickle.load(f)
        
        # Load test data
        with open(args.test_data_path, 'rb') as f:
            test_data_wrapper = pickle.load(f)
        
        # Parse configs
        try:
            training_history = json.loads(args.training_history_str)
        except:
            training_history = {}
        
        try:
            eval_config = json.loads(args.eval_config_str)
        except:
            eval_config = {}
        
        # Determine model type
        model_type = 'dcgan'
        if hasattr(gan_model, 'config'):
            if hasattr(gan_model.config, 'model_type'):
                model_type = gan_model.config.model_type
            elif hasattr(gan_model.config, 'input_dim'):
                model_type = 'vanilla_gan'
        
        print(f'Evaluating {model_type.upper()} GAN with comprehensive metrics')
        
        # Get dataset from wrapper
        test_dataset = test_data_wrapper.get('dataset')
        if not test_dataset:
            print('No test dataset found')
            test_dataset = []
        
        # Initialize metrics dictionary
        metrics = {
            'model_type': model_type,
            'evaluation_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'device': 'cuda' if torch.cuda.is_available() else 'cpu'
        }
        
        # Generate samples for evaluation
        sample_count = eval_config.get('num_samples', 100)
        generated_images = []
        
        try:
            if hasattr(gan_model, 'generator') and gan_model.generator:
                print(f'Generating {sample_count} samples for evaluation...')
                
                # Get latent dimension
                latent_dim = 100
                if hasattr(gan_model, 'config'):
                    latent_dim = getattr(gan_model.config, 'latent_dim', 100)
                
                # Generate noise
                gan_model.generator.eval()
                with torch.no_grad():
                    # Generate multiple batches
                    batch_size = min(32, sample_count)
                    for i in range(0, sample_count, batch_size):
                        current_batch = min(batch_size, sample_count - i)
                        noise = torch.randn(current_batch, latent_dim)
                        
                        # Add spatial dimensions for DCGAN
                        if model_type == 'dcgan':
                            noise = noise.view(current_batch, latent_dim, 1, 1)
                        
                        # Generate images
                        samples = gan_model.generator(noise).cpu()
                        
                        # Denormalize from [-1, 1] to [0, 1]
                        samples = (samples + 1) / 2
                        samples = torch.clamp(samples, 0, 1)
                        
                        # Convert to base64 for storage
                        for j in range(samples.size(0)):
                            sample = samples[j]
                            
                            # Determine image dimensions
                            if len(sample.shape) == 3:
                                # DCGAN format [C, H, W]
                                if sample.shape[0] == 1:
                                    img_np = sample.squeeze(0).numpy()
                                    img_pil = Image.fromarray((img_np * 255).astype(np.uint8), mode='L')
                                else:
                                    img_np = sample.permute(1, 2, 0).numpy()
                                    img_pil = Image.fromarray((img_np * 255).astype(np.uint8), mode='RGB')
                            else:
                                img_size = int(math.sqrt(sample.shape[0]))
                                img_np = sample.view(img_size, img_size).numpy()
                                img_pil = Image.fromarray((img_np * 255).astype(np.uint8), mode='L')
                            
                            # Convert to base64
                            img_bytes = io.BytesIO()
                            img_pil.save(img_bytes, format='PNG')
                            base64_data = base64.b64encode(img_bytes.getvalue()).decode('utf-8')
                            
                            # Calculate image statistics
                            img_mean = float(np.mean(img_np))
                            img_std = float(np.std(img_np))
                            
                            generated_images.append({
                                'sample_id': i + j,
                                'image_data': base64_data,
                                'model_type': model_type,
                                'filename': f'{model_type}_sample_{i+j}.png',
                                'brightness': img_mean,
                                'contrast': img_std,
                                'metrics_ready': True
                            })
                
                print(f'Generated {len(generated_images)} samples')
                
        except Exception as e:
            print(f'Error generating samples: {e}')
        
        metrics['generated_samples'] = len(generated_images)
        
        # Create evaluation report
        report_lines = []
        report_lines.append('=' * 70)
        report_lines.append(f'{model_type.upper()} GAN EVALUATION REPORT')
        report_lines.append('=' * 70)
        report_lines.append('')
        report_lines.append(f'Generated: {metrics["evaluation_time"]}')
        report_lines.append(f'Model Type: {model_type}')
        report_lines.append(f'Generated Samples: {len(generated_images)}')
        report_lines.append(f'Device: {metrics["device"]}')
        report_lines.append('')
        report_lines.append('SUMMARY:')
        report_lines.append('  Model evaluation completed successfully')
        report_lines.append('  Generated images are ready for CDN upload')
        report_lines.append('  Check metrics.json for detailed evaluation')
        report_lines.append('')
        report_lines.append('=' * 70)
        
        evaluation_report = '\\n'.join(report_lines)
        
        print(evaluation_report)
        
        # Save outputs
        os.makedirs(os.path.dirname(args.eval_metrics_path) or '.', exist_ok=True)
        with open(args.eval_metrics_path, 'w') as f:
            json.dump(metrics, f, indent=2)
        
        with open(args.generated_images_path, 'wb') as f:
            pickle.dump(generated_images, f)
        
        with open(args.evaluation_report_path, 'w') as f:
            f.write(evaluation_report)
        
        print('GAN Evaluation Complete!')
        print(f'  Metrics saved to: {args.eval_metrics_path}')
        print(f'  Generated images saved to: {args.generated_images_path}')
        print(f'  Report saved to: {args.evaluation_report_path}')

    args:
      - --trained_model_path
      - {inputPath: trained_model}
      - --test_data_path
      - {inputPath: test_data}
      - --training_history_str
      - {inputPath: training_history}
      - --eval_config_str
      - {inputValue: eval_config}
      - --eval_metrics_path
      - {outputPath: eval_metrics}
      - --generated_images_path
      - {outputPath: generated_images}
      - --evaluation_report_path
      - {outputPath: evaluation_report}
