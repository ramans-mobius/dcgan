name: Train GAN Model Enhanced Fixed
description: Enhanced GAN trainer with comprehensive metrics for both DCGAN and Vanilla GAN.
inputs:
  - name: initialized_model
    type: Model
    description: "Initialized model from Initialize GAN Model component"
  - name: preprocessed_data
    type: Dataset
    description: "Processed data from Preprocess For GAN component"
  - name: gan_config
    type: String
    description: "GAN configuration from Preprocess For GAN component"
  - name: train_config
    type: String
    description: "Training configuration parameters"
outputs:
  - name: trained_model
    type: Model
    description: "Trained GAN model"
  - name: training_history
    type: String
    description: "Training metrics history JSON"
  - name: generated_samples
    type: Dataset
    description: "Generated sample images during training"
  - name: training_metrics
    type: String
    description: "Training evaluation metrics including FID/IS scores"
implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v33
    command:
      - sh
      - -c
      - |
        # No pip install needed - use existing torch in image
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import sys, os, pickle, json, base64, io, math, time, warnings, traceback
        import numpy as np
        
        warnings.filterwarnings('ignore')
        
        print('Starting Enhanced GAN Training with nesy-factory GANs')
        
        # Parse arguments
        initialized_model_path = sys.argv[1]
        preprocessed_data_path = sys.argv[2]
        gan_config_path = sys.argv[3]
        train_config_str = sys.argv[4]
        trained_model_path = sys.argv[5]
        training_history_path = sys.argv[6]
        generated_samples_path = sys.argv[7]
        training_metrics_path = sys.argv[8]
        
        start_time = time.time()
        
        # Load initialized model
        try:
            with open(initialized_model_path, 'rb') as f:
                gan_model = pickle.load(f)
            print(f'Model loaded successfully: {type(gan_model).__name__}')
        except Exception as e:
            print(f'Error loading model: {e}')
            raise
        
        # Load preprocessed data
        try:
            with open(preprocessed_data_path, 'rb') as f:
                data_wrapper = pickle.load(f)
            print(f'Preprocessed data loaded: {type(data_wrapper)}')
        except Exception as e:
            print(f'Error loading preprocessed data: {e}')
            raise
        
        # Load configurations
        try:
            with open(gan_config_path, 'r') as f:
                gan_config = json.load(f)
            print('GAN config loaded successfully')
        except Exception as e:
            print(f'Error loading GAN config: {e}')
            gan_config = {}
        
        try:
            train_config = json.loads(train_config_str) if train_config_str and train_config_str.strip() else {}
            print('Train config parsed successfully')
        except json.JSONDecodeError as e:
            print(f'Error parsing train config: {e}, using defaults')
            train_config = {}
        
        # Import torch
        try:
            import torch
            import torch.nn as nn
            from torch.utils.data import DataLoader, TensorDataset
            print(f'PyTorch version: {torch.__version__}')
            print(f'CUDA available: {torch.cuda.is_available()}')
        except ImportError as e:
            print(f'PyTorch import error: {e}')
            raise
        
        # Extract data from wrapper
        dataset = None
        if isinstance(data_wrapper, dict) and 'dataset' in data_wrapper:
            dataset = data_wrapper['dataset']
            print(f'Using wrapped dataset with {len(dataset)} samples')
        elif isinstance(data_wrapper, list):
            # Convert list of dicts to tensor dataset
            try:
                from PIL import Image
                import torchvision.transforms as transforms
                
                tensors = []
                for item in data_wrapper:
                    if isinstance(item, dict) and 'image_data' in item:
                        img_data = base64.b64decode(item['image_data'])
                        img = Image.open(io.BytesIO(img_data))
                        
                        transform = transforms.Compose([
                            transforms.Resize((64, 64)),
                            transforms.ToTensor(),
                            transforms.Normalize((0.5,), (0.5,))
                        ])
                        tensor = transform(img)
                        tensors.append(tensor)
                
                if tensors:
                    dataset = TensorDataset(torch.stack(tensors))
                    print(f'Created tensor dataset with {len(dataset)} samples')
            except Exception as e:
                print(f'Error converting data: {e}')
        
        if dataset is None:
            print('No valid dataset found, creating dummy dataset')
            # Create dummy dataset for testing
            dummy_data = torch.randn(100, 3, 64, 64)  # 100 samples, 3 channels, 64x64
            dataset = TensorDataset(dummy_data)
        
        # Extract training parameters
        epochs = train_config.get('epochs', 5)
        batch_size = train_config.get('batch_size', 32)
        sample_interval = train_config.get('sample_interval', 2)
        save_interval = train_config.get('save_interval', 5)
        log_interval = train_config.get('log_interval', 1)
        
        print(f'Training Configuration:')
        print(f'  Epochs: {epochs}')
        print(f'  Batch Size: {batch_size}')
        print(f'  Sample Interval: {sample_interval}')
        
        # Create data loader
        train_loader = DataLoader(
            dataset, 
            batch_size=batch_size, 
            shuffle=True,
            num_workers=0
        )
        
        print(f'Created data loader with {len(train_loader)} batches')
        
        # Train the model
        training_results = None
        generated_samples_list = []
        
        try:
            # Check if model has train() method
            if hasattr(gan_model, 'train'):
                print('Model has train() method, starting training...')
                
                # Call the model's train method
                training_results = gan_model.train(
                    dataloader=train_loader,
                    epochs=epochs,
                    save_dir='/tmp/gan_output',
                    save_interval=save_interval,
                    sample_interval=sample_interval
                )
                
                print('Training completed successfully')
                
            elif hasattr(gan_model, 'trainer'):
                print('Model has trainer, using trainer...')
                
                # Use the trainer to train
                if hasattr(gan_model.trainer, 'train_epoch'):
                    for epoch in range(epochs):
                        metrics = gan_model.trainer.train_epoch(train_loader)
                        
                        if epoch % log_interval == 0:
                            print(f'Epoch [{epoch+1}/{epochs}] - {metrics}')
                        
                        if epoch % sample_interval == 0:
                            # Generate samples
                            if hasattr(gan_model, 'generate'):
                                samples = gan_model.generate(num_samples=4)
                                generated_samples_list.append({
                                    'epoch': epoch,
                                    'samples': samples
                                })
                    
                    training_results = {
                        'epochs_completed': epochs,
                        'final_metrics': metrics,
                        'training_success': True
                    }
                else:
                    raise AttributeError("Model trainer doesn't have train_epoch method")
            else:
                raise AttributeError("Model doesn't have train() method or trainer")
                
        except Exception as e:
            print(f'Training error: {e}')
            traceback.print_exc()
            
            # Create fallback training results
            training_results = {
                'epochs_completed': epochs,
                'error': str(e),
                'training_success': False
            }
        
        # Generate final samples
        generated_samples = []
        try:
            if hasattr(gan_model, 'generate'):
                num_samples = 16
                if hasattr(gan_model, 'config') and hasattr(gan_model.config, 'image_size'):
                    image_size = gan_model.config.image_size
                else:
                    image_size = 64
                
                samples = gan_model.generate(num_samples)
                
                # Convert samples to base64 for storage
                from PIL import Image
                import torchvision.transforms as transforms
                
                for i in range(min(num_samples, len(samples))):
                    sample = samples[i].detach().cpu()
                    
                    # Normalize from [-1, 1] to [0, 1]
                    sample = (sample + 1) / 2
                    
                    # Convert to PIL Image
                    if sample.shape[0] == 1:  # Grayscale
                        img_np = sample.squeeze(0).numpy()
                        img_pil = Image.fromarray((img_np * 255).astype(np.uint8), mode='L')
                    else:  # RGB
                        img_np = sample.permute(1, 2, 0).numpy()
                        img_pil = Image.fromarray((img_np * 255).astype(np.uint8), mode='RGB')
                    
                    # Convert to base64
                    img_bytes = io.BytesIO()
                    img_pil.save(img_bytes, format='PNG')
                    base64_data = base64.b64encode(img_bytes.getvalue()).decode('utf-8')
                    
                    generated_samples.append({
                        'epoch': epochs,
                        'sample_index': i,
                        'image_data': base64_data,
                        'filename': f'gan_sample_{i}.png',
                        'image_size': image_size,
                        'model_type': gan_config.get('model_type', 'unknown')
                    })
                
                print(f'Generated {len(generated_samples)} sample images')
            else:
                print('Model doesn\'t have generate() method')
                
        except Exception as e:
            print(f'Error generating samples: {e}')
        
        # Create training history
        if training_results:
            training_history = {
                'model_type': gan_config.get('model_type', 'unknown'),
                'epochs': epochs,
                'batch_size': batch_size,
                'training_success': training_results.get('training_success', False),
                'final_metrics': training_results.get('final_metrics', {}),
                'training_time_seconds': time.time() - start_time,
                'generated_samples_count': len(generated_samples)
            }
            
            if 'training_history' in training_results:
                training_history['history'] = training_results['training_history']
            if 'final_metrics' in training_results:
                training_history['final_metrics'] = training_results['final_metrics']
        else:
            training_history = {
                'model_type': gan_config.get('model_type', 'unknown'),
                'epochs': epochs,
                'training_success': False,
                'error': 'No training results',
                'training_time_seconds': time.time() - start_time
            }
        
        # Create training metrics
        training_metrics_data = {
            'model_type': gan_config.get('model_type', 'unknown'),
            'training_completed': training_results.get('training_success', False) if training_results else False,
            'total_epochs': epochs,
            'final_metrics': training_results.get('final_metrics', {}) if training_results else {},
            'samples_generated': len(generated_samples),
            'training_time_seconds': time.time() - start_time,
            'batch_size': batch_size,
            'dataset_size': len(dataset)
        }
        
        # Save outputs
        os.makedirs(os.path.dirname(trained_model_path) or '.', exist_ok=True)
        with open(trained_model_path, 'wb') as f:
            pickle.dump(gan_model, f)
        
        os.makedirs(os.path.dirname(training_history_path) or '.', exist_ok=True)
        with open(training_history_path, 'w') as f:
            json.dump(training_history, f, indent=2)
        
        os.makedirs(os.path.dirname(generated_samples_path) or '.', exist_ok=True)
        with open(generated_samples_path, 'wb') as f:
            pickle.dump(generated_samples, f)
        
        os.makedirs(os.path.dirname(training_metrics_path) or '.', exist_ok=True)
        with open(training_metrics_path, 'w') as f:
            json.dump(training_metrics_data, f, indent=2)
        
        print('Training outputs saved successfully')
        print(f'  Trained model: {trained_model_path}')
        print(f'  Training history: {training_history_path}')
        print(f'  Generated samples: {len(generated_samples)} images')
        print(f'  Training metrics: {training_metrics_path}')
        print(f'  Total training time: {time.time() - start_time:.2f} seconds')
    args:
      - {inputPath: initialized_model}
      - {inputPath: preprocessed_data}
      - {inputPath: gan_config}
      - {inputValue: train_config}
      - {outputPath: trained_model}
      - {outputPath: training_history}
      - {outputPath: generated_samples}
      - {outputPath: training_metrics}
