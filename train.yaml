name: Train DCGAN Model
description: Trains the DCGAN model with Traditional, CAFO, or Forward Forward methods.
inputs:
  - {name: model, type: Model}
  - {name: train_images, type: Dataset, description: "Preprocessed train images tensor"}
  - {name: config, type: String}
outputs:
  - {name: trained_model, type: Model}
  - {name: epoch_loss, type: String}
  - {name: generated_samples, type: Dataset, description: "Pickled generated samples"}
implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v32
    command:
      - python3
      - -u
      - -c
      - |
        import argparse
        import json
        import os
        import pickle
        import sys
        import torch
        import numpy as np
        from datetime import datetime

        parser = argparse.ArgumentParser()
        parser.add_argument('--model', type=str, required=True)
        parser.add_argument('--train_images', type=str, required=True)
        parser.add_argument('--config', type=str, required=True)
        parser.add_argument('--trained_model', type=str, required=True)
        parser.add_argument('--epoch_loss', type=str, required=True)
        parser.add_argument('--generated_samples', type=str, required=True)
        args = parser.parse_args()

        config = json.loads(args.config)

        print("Starting DCGAN Model Training")

        with open(args.model, 'rb') as f:
            model_wrapper = pickle.load(f)
        
        if 'dcgan' not in model_wrapper:
            raise ValueError("Invalid model format. Expected DCGAN wrapper.")
        
        dcgan = model_wrapper['dcgan']
        algorithm = model_wrapper.get('algorithm', 'backprop')

        with open(args.train_images, 'rb') as f:
            train_tensor = pickle.load(f)
        
        if train_tensor is None:
            raise ValueError("No train images loaded")
        
        print(f"Loaded train images tensor with shape: {train_tensor.shape}")
        
        import torch.utils.data as data
        batch_size = config.get('batch_size', 32)
        dataset = data.TensorDataset(train_tensor)
        dataloader = data.DataLoader(dataset, batch_size=batch_size, shuffle=True)
        
        print(f"Created DataLoader: {len(dataset)} samples, batch size: {batch_size}")
        
        epochs = config.get('epochs', 50)
        sample_interval = config.get('sample_interval', 5)
        
        print(f"Training Parameters:")
        print(f"  Algorithm: {algorithm.upper()}")
        print(f"  Epochs: {epochs}")
        print(f"  Batch Size: {batch_size}")
        
        training_history = {
            'epoch_losses': [],
            'd_losses': [],
            'g_losses': [],
            'real_scores': [],
            'fake_scores': [],
            'epoch_times': []
        }
        
        final_generated_samples = None
        
        print("Starting training loop...")
        
        for epoch in range(epochs):
            epoch_start = datetime.now()
            
            if epoch % 5 == 0 or epoch == 0 or epoch == epochs - 1:
                print(f"Epoch {epoch+1}/{epochs}")
            
            metrics = dcgan.trainer.train_epoch(dataloader)
            
            training_history['d_losses'].append(metrics.get('d_loss', 0))
            training_history['g_losses'].append(metrics.get('g_loss', 0))
            training_history['real_scores'].append(metrics.get('real_score', 0))
            training_history['fake_scores'].append(metrics.get('fake_score', 0))
            
            epoch_loss = metrics.get('d_loss', 0) + metrics.get('g_loss', 0)
            training_history['epoch_losses'].append(epoch_loss)
            
            epoch_time = (datetime.now() - epoch_start).total_seconds()
            training_history['epoch_times'].append(epoch_time)
            
            if epoch % 5 == 0 or epoch == 0 or epoch == epochs - 1:
                print(f"  D Loss: {metrics.get('d_loss', 0):.4f}, G Loss: {metrics.get('g_loss', 0):.4f}")
            
            if (epoch % sample_interval == 0) or (epoch == epochs - 1):
                print(f"  Generating samples...")
                with torch.no_grad():
                    dcgan.trainer.generator.eval()
                    samples = dcgan.generate(num_samples=16)
                    
                    if epoch == epochs - 1:
                        final_generated_samples = samples.cpu()
                        print(f"  Saved final generated samples")
                    
                    dcgan.trainer.generator.train()
        
        print("Training Completed Successfully!")
        
        if final_generated_samples is not None:
            with open(args.generated_samples, 'wb') as f:
                pickle.dump(final_generated_samples, f)
            print(f"Saved generated samples to: {args.generated_samples}")
        
        training_summary = {
            'training_mode': algorithm,
            'total_epochs': epochs,
            'final_d_loss': training_history['d_losses'][-1] if training_history['d_losses'] else 0,
            'final_g_loss': training_history['g_losses'][-1] if training_history['g_losses'] else 0,
            'final_epoch_loss': training_history['epoch_losses'][-1] if training_history['epoch_losses'] else 0,
            'average_epoch_time': np.mean(training_history['epoch_times']) if training_history['epoch_times'] else 0,
            'total_training_time': sum(training_history['epoch_times']),
            'loss_history': training_history,
            'training_parameters': config,
            'data_used': {
                'samples': len(dataset),
                'image_size': train_tensor.shape[2],
                'channels': train_tensor.shape[1]
            }
        }
        
        model_wrapper['training_history'] = training_summary
        model_wrapper['trained'] = True
        model_wrapper['training_completed'] = datetime.now().isoformat()
        
        output_dir = os.path.dirname(args.trained_model)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        
        with open(args.trained_model, 'wb') as f:
            pickle.dump(model_wrapper, f)
        
        print(f"Saved trained DCGAN model to: {args.trained_model}")
        
        output_dir_loss = os.path.dirname(args.epoch_loss)
        if output_dir_loss and not os.path.exists(output_dir_loss):
            os.makedirs(output_dir_loss, exist_ok=True)
        
        with open(args.epoch_loss, 'w') as f:
            json.dump(training_summary, f, indent=2)
        
        print(f"Saved training summary to: {args.epoch_loss}")
        
        print(f"Training Summary:")
        print(f"  Method: {algorithm.upper()}")
        print(f"  Total Epochs: {epochs}")
        print(f"  Final D Loss: {training_summary['final_d_loss']:.4f}")
        print(f"  Final G Loss: {training_summary['final_g_loss']:.4f}")
        print(f"  Total Training Time: {training_summary['total_training_time']:.2f}s")
        
      - --model
      - {inputPath: model}
      - --train_images
      - {inputPath: train_images}
      - --config
      - {inputValue: config}
      - --trained_model
      - {outputPath: trained_model}
      - --epoch_loss
      - {outputPath: epoch_loss}
      - --generated_samples
      - {outputPath: generated_samples}
