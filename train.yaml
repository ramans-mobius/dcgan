name: Train DCGAN Model
description: Trains the DCGAN model with Traditional, CAFO, or Forward Forward methods.
inputs:
  - {name: model, type: Model}
  - {name: train_images, type: Dataset, description: "Preprocessed train images tensor"}
  - {name: config, type: String}
outputs:
  - {name: trained_model, type: Model}
  - {name: epoch_loss, type: String}
  - {name: generated_samples, type: Dataset, description: "Pickled generated samples for CDN upload"}
implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v32
    command:
      - python3
      - -u
      - -c
    args:
      - |
        import argparse
        import json
        import os
        import pickle
        import sys
        import torch
        import numpy as np
        from datetime import datetime
        import traceback

        parser = argparse.ArgumentParser()
        parser.add_argument('--model', type=str, required=True)
        parser.add_argument('--train_images', type=str, required=True)
        parser.add_argument('--config', type=str, required=True)
        parser.add_argument('--trained_model', type=str, required=True)
        parser.add_argument('--epoch_loss', type=str, required=True)
        parser.add_argument('--generated_samples', type=str, required=True)
        args = parser.parse_args()

        config = json.loads(args.config)

        print("Starting DCGAN Model Training")
        print(f"Train images: {args.train_images}")

        # Load model wrapper
        try:
            with open(args.model, 'rb') as f:
                model_wrapper = pickle.load(f)
            
            if 'dcgan' not in model_wrapper:
                raise ValueError("Invalid model format. Expected DCGAN wrapper.")
            
            dcgan = model_wrapper['dcgan']
            original_config = model_wrapper['config']
            
            print(f"Loaded DCGAN model")
            print(f"Algorithm: {original_config.get('training_algorithm', 'backprop')}")
            
        except Exception as e:
            print(f"Failed to load model: {e}")
            raise

        # Load preprocessed train images
        print("Loading preprocessed train images...")
        try:
            with open(args.train_images, 'rb') as f:
                train_tensor = pickle.load(f)
            
            if train_tensor is None:
                raise ValueError("No train images loaded")
            
            print(f"Loaded train images tensor with shape: {train_tensor.shape}")
            
            # Create DataLoader
            import torch.utils.data as data
            batch_size = original_config.get('batch_size', 32)
            dataset = data.TensorDataset(train_tensor)
            dataloader = data.DataLoader(dataset, batch_size=batch_size, shuffle=True)
            
            print(f"Created DataLoader: {len(dataset)} samples, batch size: {batch_size}")
            
        except Exception as e:
            print(f"Failed to load train images: {e}")
            raise

        # Prepare training parameters
        epochs = config.get('epochs', original_config.get('epochs', 50))
        sample_interval = config.get('sample_interval', 5)
        
        print(f"Training Parameters:")
        print(f"  Epochs: {epochs}")
        print(f"  Batch Size: {batch_size}")
        print(f"  Learning Rate: {original_config.get('learning_rate', 0.0002)}")
        print(f"  Algorithm: {original_config.get('training_algorithm', 'backprop').upper()}")
        
        # Training history
        training_history = {
            'epoch_losses': [],
            'd_losses': [],
            'g_losses': [],
            'real_scores': [],
            'fake_scores': [],
            'epoch_times': []
        }
        
        # Store generated samples from last epoch
        final_generated_samples = None
        
        try:
            print("Starting training loop...")
            
            for epoch in range(epochs):
                epoch_start = datetime.now()
                
                if epoch % 5 == 0 or epoch == 0 or epoch == epochs - 1:
                    print(f"Epoch {epoch+1}/{epochs}")
                
                # Train one epoch
                metrics = dcgan.trainer.train_epoch(dataloader)
                
                # Record metrics
                training_history['d_losses'].append(metrics.get('d_loss', 0))
                training_history['g_losses'].append(metrics.get('g_loss', 0))
                training_history['real_scores'].append(metrics.get('real_score', 0))
                training_history['fake_scores'].append(metrics.get('fake_score', 0))
                
                epoch_loss = metrics.get('d_loss', 0) + metrics.get('g_loss', 0)
                training_history['epoch_losses'].append(epoch_loss)
                
                epoch_time = (datetime.now() - epoch_start).total_seconds()
                training_history['epoch_times'].append(epoch_time)
                
                if epoch % 5 == 0 or epoch == 0 or epoch == epochs - 1:
                    print(f"  D Loss: {metrics.get('d_loss', 0):.4f}, G Loss: {metrics.get('g_loss', 0):.4f}")
                    print(f"  Real Score: {metrics.get('real_score', 0):.4f}, Fake Score: {metrics.get('fake_score', 0):.4f}")
                
                # Generate samples at intervals and save final samples
                if (epoch % sample_interval == 0) or (epoch == epochs - 1):
                    print(f"  Generating samples...")
                    with torch.no_grad():
                        dcgan.trainer.generator.eval()
                        samples = dcgan.generate(num_samples=16)
                        
                        if epoch == epochs - 1:
                            final_generated_samples = samples.cpu()
                            print(f"  Saved final generated samples")
                        
                        dcgan.trainer.generator.train()
            
            print("Training Completed Successfully!")
            
            # Save final generated samples
            if final_generated_samples is not None:
                with open(args.generated_samples, 'wb') as f:
                    pickle.dump(final_generated_samples, f)
                print(f"Saved generated samples to: {args.generated_samples}")
            
            # Create training summary
            training_summary = {
                'training_mode': original_config.get('training_algorithm', 'backprop'),
                'total_epochs': epochs,
                'final_d_loss': training_history['d_losses'][-1] if training_history['d_losses'] else 0,
                'final_g_loss': training_history['g_losses'][-1] if training_history['g_losses'] else 0,
                'final_epoch_loss': training_history['epoch_losses'][-1] if training_history['epoch_losses'] else 0,
                'average_epoch_time': np.mean(training_history['epoch_times']) if training_history['epoch_times'] else 0,
                'total_training_time': sum(training_history['epoch_times']),
                'loss_history': training_history,
                'training_parameters': {
                    'batch_size': batch_size,
                    'learning_rate': original_config.get('learning_rate', 0.0002),
                    'n_critic': original_config.get('n_critic', 5),
                    'use_wgan': original_config.get('use_wgan', False)
                },
                'model_config': original_config,
                'data_used': {
                    'samples': len(dataset),
                    'image_size': train_tensor.shape[2],
                    'channels': train_tensor.shape[1]
                }
            }
            
            # Update model wrapper with training results
            model_wrapper['training_history'] = training_summary
            model_wrapper['trained'] = True
            model_wrapper['training_completed'] = datetime.now().isoformat()
            
            # Save trained model
            output_dir = os.path.dirname(args.trained_model)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir, exist_ok=True)
            
            with open(args.trained_model, 'wb') as f:
                pickle.dump(model_wrapper, f)
            
            print(f"Saved trained DCGAN model to: {args.trained_model}")
            
            # Save epoch loss data
            output_dir_loss = os.path.dirname(args.epoch_loss)
            if output_dir_loss and not os.path.exists(output_dir_loss):
                os.makedirs(output_dir_loss, exist_ok=True)
            
            with open(args.epoch_loss, 'w') as f:
                json.dump(training_summary, f, indent=2)
            
            print(f"Saved training summary to: {args.epoch_loss}")
            
            # Print final summary
            print(f"Training Summary:")
            print(f"  Method: {training_summary['training_mode'].upper()}")
            print(f"  Total Epochs: {epochs}")
            print(f"  Final D Loss: {training_summary['final_d_loss']:.4f}")
            print(f"  Final G Loss: {training_summary['final_g_loss']:.4f}")
            print(f"  Total Training Time: {training_summary['total_training_time']:.2f}s")
            print(f"  Data Used: {training_summary['data_used']['samples']} images")
            
        except Exception as e:
            print(f"Error during training: {e}")
            traceback.print_exc()
            
            # Save partial results if possible
            if 'training_history' in locals() and model_wrapper:
                model_wrapper['training_error'] = str(e)
                model_wrapper['partial_training'] = True
                
                # Save partial model
                with open(args.trained_model, 'wb') as f:
                    pickle.dump(model_wrapper, f)
                
                # Save partial training summary
                partial_summary = {
                    'error': str(e),
                    'epochs_completed': len(training_history.get('epoch_losses', [])),
                    'partial_history': training_history
                }
                
                with open(args.epoch_loss, 'w') as f:
                    json.dump(partial_summary, f, indent=2)
                
                print(f"Saved partial results due to error")
            
            raise
      - --model
      - {inputPath: model}
      - --train_images
      - {inputPath: train_images}
      - --config
      - {inputValue: config}
      - --trained_model
      - {outputPath: trained_model}
      - --epoch_loss
      - {outputPath: epoch_loss}
      - --generated_samples
      - {outputPath: generated_samples}
